{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "In this notebook, we will create datasets for later demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below is the workflow that SeqAL works with annotation tool.\n",
    "\n",
    "![al_cycle_v2.png](../docs/images/al_cycle_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Mode and Annotation Mode\n",
    "\n",
    "According to the workflow, we have to provide 4 datasets, 3 labeled datasets and 1 unlabeled dataset. We call this mode as **annotation mode**.\n",
    "\n",
    "- labeled datasets\n",
    "    1. seed data: a dataset used for training model\n",
    "    2. validation data: a dataset used to validate model performance in training process\n",
    "    3. test data: a dataset used to test best model performance\n",
    "- unlabeled datasets\n",
    "    1. unlabeled data pool: a dataset contains unlabeled data\n",
    "\n",
    "If we just want to simulate the active learning cycle, we should provide `labeled data pool` instead of `unlabeled data pool`.\n",
    "\n",
    "- labeled datasets\n",
    "    1. seed data: a dataset used for training model\n",
    "    2. validation data: a dataset used to validate model performance in training process\n",
    "    3. test data: a dataset used to test best model performance\n",
    "    4. labeled data pool: a dataset contains gold labels to simulate real annotation work\n",
    "\n",
    "We call this mode as **research mode**.\n",
    "\n",
    "More detail of two modes can be found in [TUTORIAL_5_Research_and_Annotation_Mode](../docs/TUTORIAL_5_Research_and_Annotation_Mode.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Public Dataset\n",
    "\n",
    "If the domain of our data is specific and there are no public labeled datasets, we should first annnotate the `seed data`, `validation data`, `test data` by ourselves. \n",
    "\n",
    "\n",
    "If the domain of our data is same with the domain of other public datasets, there is no need to prepare the labeled data by ourselves. We can download the dataset directly. For example, we download CoNLL-03 from [homepage](https://www.clips.uantwerpen.be/conll2003/ner/) and put the `eng.testa`, `eng.testb`, `eng.train` to `data/conll_03` floder.\n",
    "\n",
    "We can load the corpus by below script.\n",
    "\n",
    "\n",
    "```python\n",
    "from seqal.datasets import ColumnCorpus\n",
    "\n",
    "columns = {0: \"text\", 3: \"ner\"}\n",
    "data_folder = \"../data/conll_03\"\n",
    "corpus = ColumnCorpus(\n",
    "    data_folder,\n",
    "    columns,\n",
    "    train_file=\"eng.train\",\n",
    "    dev_file=\"eng.testa\",\n",
    "    test_file=\"eng.testb\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flair also provides some [Named Entity Recognition (NER) datasets](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md#datasets-included-in-flair).\n",
    "\n",
    "We can download it by below script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-07 01:06:58,168 Reading data from /Users/smap/.flair/datasets/ner_english_movie_simple\n",
      "2022-09-07 01:06:58,170 Train: /Users/smap/.flair/datasets/ner_english_movie_simple/engtrain.bio\n",
      "2022-09-07 01:06:58,171 Dev: None\n",
      "2022-09-07 01:06:58,172 Test: /Users/smap/.flair/datasets/ner_english_movie_simple/engtest.bio\n",
      "Corpus: 8797 train + 978 dev + 2443 test sentences\n"
     ]
    }
   ],
   "source": [
    "import flair.datasets\n",
    "corpus = flair.datasets.NER_ENGLISH_MOVIE_SIMPLE()\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The message shows where the datasets are stored. We put the `engtrain.bio`, `engtest.bio` to `data/ner_english_movie_simple` floder.\n",
    "\n",
    "Below is a sentence example in `engtrain.bio`. The first column is label. The second column is text.\n",
    "\n",
    "```\n",
    "O\twhat\n",
    "O\tmovies\n",
    "O\tstar\n",
    "B-ACTOR\tbruce\n",
    "I-ACTOR\twillis\n",
    "```\n",
    "\n",
    "This datasets does not contain validation (dev) file, but it will create validation dataset by selecting data from training dataset. So the `engtrain.bio` contains 9775 data samples.\n",
    "\n",
    "The `print(corpus)` will show the number of data samples in each dataset.\n",
    "\n",
    "We will use this dataset to create the labeled dataset and unlabeled dataset used for demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "\n",
    "The training dataset contains 9775 data samples. Usually, a seed data contains a small number of data. So we split 10% of the training data as labaled seed data, 10% as validation data, and 80% as data pool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9775\n"
     ]
    }
   ],
   "source": [
    "from seqal.datasets import ColumnDataset\n",
    "\n",
    "columns = {0: \"ner\", 1: \"text\"}\n",
    "pool_file = \"../data/ner_english_movie_simple/engtrain.bio\"\n",
    "data_pool = ColumnDataset(pool_file, columns)\n",
    "print(len(data_pool.sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "indices = np.arange(len(data_pool.sentences))\n",
    "np.random.shuffle(indices)\n",
    "seed_end = int(len(indices) * 0.1)\n",
    "\n",
    "seed_data = data_pool.sentences[:seed_end]\n",
    "validation_data = data_pool.sentences[seed_end:2*seed_end]\n",
    "data_pool = data_pool.sentences[2*seed_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `seed_data` and `validation_data` are labeled data, we could use below script to save them as CoNLL format.\n",
    "\n",
    "We save `data_pool` to both CoNLL format wtih labels and plain text without labels. They are used on different active learning mode. In the research mode, there is no annotation tool. The `data_pool` have to contains gold labels to simulate the annotation step. In the annotation mode, we will select data from unlabled dataset and transfer the data to annotation tool. So the `data_pool` should be a plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqal.utils import output_labeled_data\n",
    "\n",
    "seed_data_path = \"../data/ner_english_movie_simple/engtrain_seed.bio\"\n",
    "validation_data_path = \"../data/ner_english_movie_simple/engtrain_dev.bio\"\n",
    "data_pool_path = \"../data/ner_english_movie_simple/labeled_data_pool.bio\"\n",
    "\n",
    "\n",
    "output_labeled_data(seed_data, seed_data_path, file_format=\"conll\", tag_type=\"ner\")\n",
    "output_labeled_data(validation_data, validation_data_path, file_format=\"conll\", tag_type=\"ner\")\n",
    "output_labeled_data(data_pool, data_pool_path, file_format=\"conll\", tag_type=\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the test data and reorder the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {0: \"ner\", 1: \"text\"}\n",
    "test_file = \"../data/ner_english_movie_simple/engtest.bio\"\n",
    "test_data = ColumnDataset(test_file, columns)\n",
    "\n",
    "test_data_path = \"../data/ner_english_movie_simple/engtest.bio\"\n",
    "output_labeled_data(test_data, test_data_path, file_format=\"conll\", tag_type=\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the `data_pool` with plain text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_plain_text(sentences: list, file_path: str) -> None:\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for sentence in sentences:\n",
    "            file.write(sentence.to_plain_string())\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "unlabeled_data_pool_path = \"../data/ner_english_movie_simple/unlabeled_data_pool.txt\"\n",
    "output_plain_text(data_pool, unlabeled_data_pool_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In each mode, we provide below datasets.\n",
    "\n",
    "- Research mode:\n",
    "  - labeled data:\n",
    "      - seed data: `engtrain_seed.bio`\n",
    "      - validation data: `engtrain_dev.bio`\n",
    "      - test data: `engtest.bio`\n",
    "      - labeled data pool: `labeled_data_pool.bio`\n",
    "\n",
    "\n",
    "- Annotation mode:\n",
    "  - labeled data:\n",
    "      - seed data: `engtrain_seed.bio`\n",
    "      - validation data: `engtrain_dev.bio`\n",
    "      - test data: `engtest.bio`\n",
    "  - unlabeled data:\n",
    "      - unlabeled data pool: `unlabeled_data_pool.txt`\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e065247030c9216ed33624f20c54f671a416ca6030785113c75cd1b8e233e922"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seqal-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
