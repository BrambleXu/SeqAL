{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Cycle in Research Mode\n",
    "\n",
    "In this notebook, we will introduce how to use the research mode. The research mode means that we skip the human related annotation step and simulate the active learning cycle without third part annotation tool.\n",
    "\n",
    "Below is the workflow of research mode.\n",
    "\n",
    "![al_cycle_research_mode.png](../docs/images/al_cycle_research_mode.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SeqAL workflow without annotation tool:\n",
    "\n",
    "- Step1: SeqAL initialize model by corpus\n",
    "- Step2: Model predicts on unlabeled data\n",
    "- Step3: SeqAL select informative data from data pool according to the predictions in step2.\n",
    "- Step4: Replace the predicted labels with gold annotations to simulate the annotation process.\n",
    "- Step6: SeqAL add the annotated data to labeled data\n",
    "- Step7: Retrain the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created below datasets for research mode.\n",
    "\n",
    "\n",
    "- labeled data:\n",
    "    - seed data: `engtrain_seed.bio`\n",
    "    - validation data: `engtrain_dev.bio`\n",
    "    - test data: `engtest.bio`\n",
    "    - labeled data pool: `labeled_data_pool.bio`\n",
    "\n",
    "\n",
    "You can find the detail of creation process in the `data_preparation.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus\n",
    "\n",
    "We load below datasets by the following script.\n",
    "\n",
    "- seed data: `engtrain_seed.bio`\n",
    "- validation data: `engtrain_dev.bio`\n",
    "- test data: `engtest.bio`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-07 01:18:28,909 Reading data from ../data/ner_english_movie_simple\n",
      "2022-09-07 01:18:28,911 Train: ../data/ner_english_movie_simple/engtrain_seed.bio\n",
      "2022-09-07 01:18:28,912 Dev: ../data/ner_english_movie_simple/engtrain_dev.bio\n",
      "2022-09-07 01:18:28,912 Test: ../data/ner_english_movie_simple/engtest.bio\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "from seqal.active_learner import ActiveLearner\n",
    "from seqal.datasets import ColumnCorpus, ColumnDataset\n",
    "from seqal.samplers import LeastConfidenceSampler\n",
    "\n",
    "\n",
    "# 1. get the corpus\n",
    "columns = {0: \"text\", 1: \"ner\"}\n",
    "data_folder = \"../data/ner_english_movie_simple\"\n",
    "corpus = ColumnCorpus(\n",
    "    data_folder,\n",
    "    columns,\n",
    "    train_file=\"engtrain_seed.bio\",\n",
    "    dev_file=\"engtrain_dev.bio\",\n",
    "    test_file=\"engtest.bio\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Active Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-07 01:18:38,559 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,560 Model: \"SequenceTagger(\n",
      "  (embeddings): WordEmbeddings(\n",
      "    'glove'\n",
      "    (embedding): Embedding(400001, 100)\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-09-07 01:18:38,561 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,562 Corpus: \"Corpus: 977 train + 977 dev + 2443 test sentences\"\n",
      "2022-09-07 01:18:38,562 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,564 Parameters:\n",
      "2022-09-07 01:18:38,565  - learning_rate: \"0.1\"\n",
      "2022-09-07 01:18:38,566  - mini_batch_size: \"32\"\n",
      "2022-09-07 01:18:38,566  - patience: \"5\"\n",
      "2022-09-07 01:18:38,567  - anneal_factor: \"0.5\"\n",
      "2022-09-07 01:18:38,568  - max_epochs: \"1\"\n",
      "2022-09-07 01:18:38,569  - shuffle: \"True\"\n",
      "2022-09-07 01:18:38,570  - train_with_dev: \"False\"\n",
      "2022-09-07 01:18:38,570  - batch_growth_annealing: \"False\"\n",
      "2022-09-07 01:18:38,571 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,572 Model training base path: \"output/init_train\"\n",
      "2022-09-07 01:18:38,573 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,574 Device: cpu\n",
      "2022-09-07 01:18:38,576 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,579 Embeddings storage mode: cpu\n",
      "2022-09-07 01:18:38,582 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:38,734 epoch 1 - iter 3/31 - loss 2.98049898 - samples/sec: 638.32 - lr: 0.100000\n",
      "2022-09-07 01:18:38,813 epoch 1 - iter 6/31 - loss 2.48576678 - samples/sec: 1240.59 - lr: 0.100000\n",
      "2022-09-07 01:18:38,898 epoch 1 - iter 9/31 - loss 2.32231235 - samples/sec: 1148.35 - lr: 0.100000\n",
      "2022-09-07 01:18:38,973 epoch 1 - iter 12/31 - loss 2.19822552 - samples/sec: 1337.97 - lr: 0.100000\n",
      "2022-09-07 01:18:39,056 epoch 1 - iter 15/31 - loss 2.12630867 - samples/sec: 1180.26 - lr: 0.100000\n",
      "2022-09-07 01:18:39,136 epoch 1 - iter 18/31 - loss 2.06459619 - samples/sec: 1216.45 - lr: 0.100000\n",
      "2022-09-07 01:18:39,201 epoch 1 - iter 21/31 - loss 2.03540587 - samples/sec: 1536.07 - lr: 0.100000\n",
      "2022-09-07 01:18:39,275 epoch 1 - iter 24/31 - loss 1.98364176 - samples/sec: 1319.12 - lr: 0.100000\n",
      "2022-09-07 01:18:39,351 epoch 1 - iter 27/31 - loss 1.93478426 - samples/sec: 1274.95 - lr: 0.100000\n",
      "2022-09-07 01:18:39,423 epoch 1 - iter 30/31 - loss 1.89711381 - samples/sec: 1371.25 - lr: 0.100000\n",
      "2022-09-07 01:18:39,440 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:39,441 EPOCH 1 done: loss 1.8882 - lr 0.1000000\n",
      "2022-09-07 01:18:40,163 DEV : loss 1.388966679573059 - f1-score (micro avg)  0.0098\n",
      "2022-09-07 01:18:40,176 BAD EPOCHS (no improvement): 0\n",
      "2022-09-07 01:18:40,178 saving best model\n",
      "2022-09-07 01:18:41,409 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:18:41,410 loading file output/init_train/best-model.pt\n",
      "2022-09-07 01:18:44,787 0.0318\t0.0079\t0.0126\t0.0065\n",
      "2022-09-07 01:18:44,788 \n",
      "Results:\n",
      "- F-score (micro) 0.0126\n",
      "- F-score (macro) 0.0056\n",
      "- Accuracy 0.0065\n",
      "\n",
      "By class:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          ACTOR     0.0277    0.0333    0.0302       812\n",
      "          GENRE     0.1143    0.0072    0.0135      1117\n",
      "           YEAR     0.2500    0.0014    0.0028       720\n",
      "       DIRECTOR     0.0000    0.0000    0.0000       456\n",
      "           PLOT     0.0741    0.0122    0.0210       491\n",
      "          TITLE     0.0000    0.0000    0.0000       562\n",
      "         RATING     0.0000    0.0000    0.0000       500\n",
      "RATINGS_AVERAGE     0.0000    0.0000    0.0000       451\n",
      "      CHARACTER     0.0000    0.0000    0.0000        90\n",
      "           SONG     0.0000    0.0000    0.0000        54\n",
      "         REVIEW     0.0000    0.0000    0.0000        56\n",
      "        TRAILER     0.0000    0.0000    0.0000        30\n",
      "\n",
      "      micro avg     0.0318    0.0079    0.0126      5339\n",
      "      macro avg     0.0388    0.0045    0.0056      5339\n",
      "   weighted avg     0.0687    0.0079    0.0097      5339\n",
      "    samples avg     0.0065    0.0065    0.0065      5339\n",
      "\n",
      "2022-09-07 01:18:44,789 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. tagger params\n",
    "tagger_params = {}\n",
    "tagger_params[\"tag_type\"] = \"ner\"\n",
    "tagger_params[\"hidden_size\"] = 256\n",
    "embeddings = WordEmbeddings(\"glove\")\n",
    "tagger_params[\"embeddings\"] = embeddings\n",
    "tagger_params[\"use_rnn\"] = False\n",
    "\n",
    "# 3. trainer params\n",
    "trainer_params = {}\n",
    "trainer_params[\"max_epochs\"] = 1\n",
    "trainer_params[\"mini_batch_size\"] = 32\n",
    "trainer_params[\"learning_rate\"] = 0.1\n",
    "trainer_params[\"patience\"] = 5\n",
    "\n",
    "# 4. setup active learner\n",
    "sampler = LeastConfidenceSampler()\n",
    "learner = ActiveLearner(corpus, sampler, tagger_params, trainer_params)\n",
    "\n",
    "# 5. initialize active learner\n",
    "learner.initialize(dir_path=\"output/init_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up an active learner, we have to provide `corpus`, `sampler`, `tagger_params`, and `trainer_params`. \n",
    "\n",
    "The `sampler` means the sampling method. Here we use the least confidence sampling metod (`LeastConfidenceSampler`)\n",
    "\n",
    "\n",
    "The `tagger_params` means model parameters. The default model is Bi-LSTM CRF. In order to speed up the training time, here we set the `tagger_params[\"use_rnn\"] = False`. It means that we only use the CRF model. This model is fast even in CPU.\n",
    "\n",
    "\n",
    "The `trainer_params` control the training process. We set `trainer_params[\"max_epochs\"] = 1` for demonstration. But in real case, `20` is a proper choice.\n",
    "\n",
    "\n",
    "After the setup, we can initialize the learner by calling `learner.initialize`. This will first train the model from scratch. The training log and model will be saved to `dir_path`.\n",
    "\n",
    "Related tutorial: [Active Learner Setup](../docs/TUTORIAL_3_Active_Learner_Setup.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. prepare data pool\n",
    "pool_file = data_folder + \"/labeled_data_pool.bio\"\n",
    "data_pool = ColumnDataset(pool_file, columns)\n",
    "labeled_sentences = data_pool.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are in the research mode, here we data pool is a labeled dataset. \n",
    "\n",
    "Related tutorial: [Prepare Data Pool](../docs/TUTORIAL_4_Prepare_Data_Pool.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. query setup\n",
    "query_number = 100\n",
    "token_based = False\n",
    "iterations = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query_number` means how many data samples we want to query in each iteration. \n",
    "\n",
    "The `token_based` means we query data on sentence level or token level. If `token_based` is `True`, we will query the `100` tokens  in each iteration. If `token_based` is `False`, we will query `100` sentences in each iteration. \n",
    "\n",
    "The `iterations` means how many rounds we run the active learning cycle.\n",
    "\n",
    "\n",
    "Related tutorial: [Query Setup](../docs//TUTORIAL_6_Query_Setup.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-07 01:35:46,274 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,275 Model: \"SequenceTagger(\n",
      "  (embeddings): WordEmbeddings(\n",
      "    'glove'\n",
      "    (embedding): Embedding(400001, 100)\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-09-07 01:35:46,277 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,278 Corpus: \"Corpus: 1077 train + 977 dev + 2443 test sentences\"\n",
      "2022-09-07 01:35:46,279 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,282 Parameters:\n",
      "2022-09-07 01:35:46,283  - learning_rate: \"0.1\"\n",
      "2022-09-07 01:35:46,285  - mini_batch_size: \"32\"\n",
      "2022-09-07 01:35:46,286  - patience: \"5\"\n",
      "2022-09-07 01:35:46,287  - anneal_factor: \"0.5\"\n",
      "2022-09-07 01:35:46,288  - max_epochs: \"1\"\n",
      "2022-09-07 01:35:46,288  - shuffle: \"True\"\n",
      "2022-09-07 01:35:46,289  - train_with_dev: \"False\"\n",
      "2022-09-07 01:35:46,290  - batch_growth_annealing: \"False\"\n",
      "2022-09-07 01:35:46,290 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,292 Model training base path: \"output/retrain_0\"\n",
      "2022-09-07 01:35:46,293 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,294 Device: cpu\n",
      "2022-09-07 01:35:46,297 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,299 Embeddings storage mode: cpu\n",
      "2022-09-07 01:35:46,302 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:46,396 epoch 1 - iter 3/34 - loss 2.77487894 - samples/sec: 1039.59 - lr: 0.100000\n",
      "2022-09-07 01:35:46,490 epoch 1 - iter 6/34 - loss 2.35119607 - samples/sec: 1042.29 - lr: 0.100000\n",
      "2022-09-07 01:35:46,563 epoch 1 - iter 9/34 - loss 2.19612709 - samples/sec: 1336.30 - lr: 0.100000\n",
      "2022-09-07 01:35:46,633 epoch 1 - iter 12/34 - loss 2.10270690 - samples/sec: 1407.84 - lr: 0.100000\n",
      "2022-09-07 01:35:46,735 epoch 1 - iter 15/34 - loss 2.04852462 - samples/sec: 955.23 - lr: 0.100000\n",
      "2022-09-07 01:35:46,836 epoch 1 - iter 18/34 - loss 1.99145980 - samples/sec: 962.49 - lr: 0.100000\n",
      "2022-09-07 01:35:47,131 epoch 1 - iter 21/34 - loss 1.95339082 - samples/sec: 328.34 - lr: 0.100000\n",
      "2022-09-07 01:35:47,296 epoch 1 - iter 24/34 - loss 1.90746080 - samples/sec: 609.97 - lr: 0.100000\n",
      "2022-09-07 01:35:47,464 epoch 1 - iter 27/34 - loss 1.87015489 - samples/sec: 577.32 - lr: 0.100000\n",
      "2022-09-07 01:35:47,989 epoch 1 - iter 30/34 - loss 1.82674611 - samples/sec: 184.08 - lr: 0.100000\n",
      "2022-09-07 01:35:48,444 epoch 1 - iter 33/34 - loss 1.79088649 - samples/sec: 212.73 - lr: 0.100000\n",
      "2022-09-07 01:35:48,554 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:48,555 EPOCH 1 done: loss 1.7895 - lr 0.1000000\n",
      "2022-09-07 01:35:50,158 DEV : loss 1.2885764837265015 - f1-score (micro avg)  0.239\n",
      "2022-09-07 01:35:50,171 BAD EPOCHS (no improvement): 0\n",
      "2022-09-07 01:35:50,172 saving best model\n",
      "2022-09-07 01:35:51,426 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:35:51,428 loading file output/retrain_0/best-model.pt\n",
      "2022-09-07 01:35:54,878 0.2748\t0.2622\t0.2684\t0.1668\n",
      "2022-09-07 01:35:54,879 \n",
      "Results:\n",
      "- F-score (micro) 0.2684\n",
      "- F-score (macro) 0.1285\n",
      "- Accuracy 0.1668\n",
      "\n",
      "By class:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           YEAR     0.2651    0.5597    0.3598       720\n",
      "          ACTOR     0.3194    0.4815    0.3841       812\n",
      "          GENRE     0.3823    0.2936    0.3322      1117\n",
      "         RATING     0.2647    0.4680    0.3382       500\n",
      "          TITLE     0.1164    0.0391    0.0586       562\n",
      "       DIRECTOR     0.0422    0.0219    0.0289       456\n",
      "           PLOT     0.1237    0.0244    0.0408       491\n",
      "RATINGS_AVERAGE     0.0000    0.0000    0.0000       451\n",
      "      CHARACTER     0.0000    0.0000    0.0000        90\n",
      "           SONG     0.0000    0.0000    0.0000        54\n",
      "         REVIEW     0.0000    0.0000    0.0000        56\n",
      "        TRAILER     0.0000    0.0000    0.0000        30\n",
      "\n",
      "      micro avg     0.2748    0.2622    0.2684      5339\n",
      "      macro avg     0.1262    0.1574    0.1285      5339\n",
      "   weighted avg     0.2163    0.2622    0.2205      5339\n",
      "    samples avg     0.1668    0.1668    0.1668      5339\n",
      "\n",
      "2022-09-07 01:35:54,880 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,923 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,924 Model: \"SequenceTagger(\n",
      "  (embeddings): WordEmbeddings(\n",
      "    'glove'\n",
      "    (embedding): Embedding(400001, 100)\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-09-07 01:36:00,926 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,927 Corpus: \"Corpus: 1177 train + 977 dev + 2443 test sentences\"\n",
      "2022-09-07 01:36:00,928 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,929 Parameters:\n",
      "2022-09-07 01:36:00,930  - learning_rate: \"0.1\"\n",
      "2022-09-07 01:36:00,931  - mini_batch_size: \"32\"\n",
      "2022-09-07 01:36:00,932  - patience: \"5\"\n",
      "2022-09-07 01:36:00,932  - anneal_factor: \"0.5\"\n",
      "2022-09-07 01:36:00,933  - max_epochs: \"1\"\n",
      "2022-09-07 01:36:00,934  - shuffle: \"True\"\n",
      "2022-09-07 01:36:00,935  - train_with_dev: \"False\"\n",
      "2022-09-07 01:36:00,936  - batch_growth_annealing: \"False\"\n",
      "2022-09-07 01:36:00,937 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,938 Model training base path: \"output/retrain_1\"\n",
      "2022-09-07 01:36:00,939 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,940 Device: cpu\n",
      "2022-09-07 01:36:00,941 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:00,941 Embeddings storage mode: cpu\n",
      "2022-09-07 01:36:00,944 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:01,032 epoch 1 - iter 3/37 - loss 3.37779062 - samples/sec: 1116.67 - lr: 0.100000\n",
      "2022-09-07 01:36:01,112 epoch 1 - iter 6/37 - loss 2.69007197 - samples/sec: 1217.49 - lr: 0.100000\n",
      "2022-09-07 01:36:01,186 epoch 1 - iter 9/37 - loss 2.45684501 - samples/sec: 1326.57 - lr: 0.100000\n",
      "2022-09-07 01:36:01,255 epoch 1 - iter 12/37 - loss 2.29561834 - samples/sec: 1424.28 - lr: 0.100000\n",
      "2022-09-07 01:36:01,373 epoch 1 - iter 15/37 - loss 2.20661870 - samples/sec: 824.04 - lr: 0.100000\n",
      "2022-09-07 01:36:01,498 epoch 1 - iter 18/37 - loss 2.14580993 - samples/sec: 786.00 - lr: 0.100000\n",
      "2022-09-07 01:36:01,626 epoch 1 - iter 21/37 - loss 2.09504726 - samples/sec: 762.92 - lr: 0.100000\n",
      "2022-09-07 01:36:01,815 epoch 1 - iter 24/37 - loss 2.03603525 - samples/sec: 514.30 - lr: 0.100000\n",
      "2022-09-07 01:36:02,048 epoch 1 - iter 27/37 - loss 1.98392427 - samples/sec: 414.52 - lr: 0.100000\n",
      "2022-09-07 01:36:02,261 epoch 1 - iter 30/37 - loss 1.93666277 - samples/sec: 453.91 - lr: 0.100000\n",
      "2022-09-07 01:36:02,524 epoch 1 - iter 33/37 - loss 1.89078392 - samples/sec: 368.00 - lr: 0.100000\n",
      "2022-09-07 01:36:02,679 epoch 1 - iter 36/37 - loss 1.81814580 - samples/sec: 626.91 - lr: 0.100000\n",
      "2022-09-07 01:36:02,750 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:02,752 EPOCH 1 done: loss 1.7922 - lr 0.1000000\n",
      "2022-09-07 01:36:04,339 DEV : loss 1.4420353174209595 - f1-score (micro avg)  0.1556\n",
      "2022-09-07 01:36:04,351 BAD EPOCHS (no improvement): 0\n",
      "2022-09-07 01:36:04,353 saving best model\n",
      "2022-09-07 01:36:05,477 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:05,478 loading file output/retrain_1/best-model.pt\n",
      "2022-09-07 01:36:08,892 0.3473\t0.0996\t0.1549\t0.0869\n",
      "2022-09-07 01:36:08,894 \n",
      "Results:\n",
      "- F-score (micro) 0.1549\n",
      "- F-score (macro) 0.0741\n",
      "- Accuracy 0.0869\n",
      "\n",
      "By class:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          ACTOR     0.3684    0.4138    0.3898       812\n",
      "          GENRE     0.5000    0.0072    0.0141      1117\n",
      "           YEAR     0.5155    0.1389    0.2188       720\n",
      "         RATING     0.3460    0.1640    0.2225       500\n",
      "          TITLE     0.0000    0.0000    0.0000       562\n",
      "           PLOT     0.0000    0.0000    0.0000       491\n",
      "RATINGS_AVERAGE     0.4167    0.0111    0.0216       451\n",
      "       DIRECTOR     0.0000    0.0000    0.0000       456\n",
      "         REVIEW     0.0000    0.0000    0.0000        56\n",
      "      CHARACTER     1.0000    0.0111    0.0220        90\n",
      "           SONG     0.0000    0.0000    0.0000        54\n",
      "        TRAILER     0.0000    0.0000    0.0000        30\n",
      "\n",
      "      micro avg     0.3473    0.0996    0.1549      5339\n",
      "      macro avg     0.2622    0.0622    0.0741      5339\n",
      "   weighted avg     0.3146    0.0996    0.1148      5339\n",
      "    samples avg     0.0869    0.0869    0.0869      5339\n",
      "\n",
      "2022-09-07 01:36:08,895 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,959 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,960 Model: \"SequenceTagger(\n",
      "  (embeddings): WordEmbeddings(\n",
      "    'glove'\n",
      "    (embedding): Embedding(400001, 100)\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (linear): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2022-09-07 01:36:14,961 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,962 Corpus: \"Corpus: 1277 train + 977 dev + 2443 test sentences\"\n",
      "2022-09-07 01:36:14,963 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,964 Parameters:\n",
      "2022-09-07 01:36:14,965  - learning_rate: \"0.1\"\n",
      "2022-09-07 01:36:14,966  - mini_batch_size: \"32\"\n",
      "2022-09-07 01:36:14,967  - patience: \"5\"\n",
      "2022-09-07 01:36:14,968  - anneal_factor: \"0.5\"\n",
      "2022-09-07 01:36:14,969  - max_epochs: \"1\"\n",
      "2022-09-07 01:36:14,971  - shuffle: \"True\"\n",
      "2022-09-07 01:36:14,971  - train_with_dev: \"False\"\n",
      "2022-09-07 01:36:14,972  - batch_growth_annealing: \"False\"\n",
      "2022-09-07 01:36:14,973 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,974 Model training base path: \"output/retrain_2\"\n",
      "2022-09-07 01:36:14,974 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,975 Device: cpu\n",
      "2022-09-07 01:36:14,976 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:14,977 Embeddings storage mode: cpu\n",
      "2022-09-07 01:36:14,979 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:15,108 epoch 1 - iter 4/40 - loss 2.71811048 - samples/sec: 1011.18 - lr: 0.100000\n",
      "2022-09-07 01:36:15,204 epoch 1 - iter 8/40 - loss 2.36671861 - samples/sec: 1367.78 - lr: 0.100000\n",
      "2022-09-07 01:36:15,282 epoch 1 - iter 12/40 - loss 2.23345671 - samples/sec: 1652.16 - lr: 0.100000\n",
      "2022-09-07 01:36:15,429 epoch 1 - iter 16/40 - loss 2.14529062 - samples/sec: 885.78 - lr: 0.100000\n",
      "2022-09-07 01:36:15,689 epoch 1 - iter 20/40 - loss 2.08119080 - samples/sec: 495.33 - lr: 0.100000\n",
      "2022-09-07 01:36:15,944 epoch 1 - iter 24/40 - loss 2.02809512 - samples/sec: 506.13 - lr: 0.100000\n",
      "2022-09-07 01:36:16,132 epoch 1 - iter 28/40 - loss 1.96241871 - samples/sec: 693.64 - lr: 0.100000\n",
      "2022-09-07 01:36:16,435 epoch 1 - iter 32/40 - loss 1.92852249 - samples/sec: 439.17 - lr: 0.100000\n",
      "2022-09-07 01:36:16,651 epoch 1 - iter 36/40 - loss 1.86865500 - samples/sec: 596.99 - lr: 0.100000\n",
      "2022-09-07 01:36:16,933 epoch 1 - iter 40/40 - loss 1.81739444 - samples/sec: 456.14 - lr: 0.100000\n",
      "2022-09-07 01:36:16,935 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:16,936 EPOCH 1 done: loss 1.8174 - lr 0.1000000\n",
      "2022-09-07 01:36:18,641 DEV : loss 1.3900419473648071 - f1-score (micro avg)  0.1711\n",
      "2022-09-07 01:36:18,653 BAD EPOCHS (no improvement): 0\n",
      "2022-09-07 01:36:18,655 saving best model\n",
      "2022-09-07 01:36:19,744 ----------------------------------------------------------------------------------------------------\n",
      "2022-09-07 01:36:19,745 loading file output/retrain_2/best-model.pt\n",
      "2022-09-07 01:36:23,413 0.268\t0.2366\t0.2513\t0.1522\n",
      "2022-09-07 01:36:23,414 \n",
      "Results:\n",
      "- F-score (micro) 0.2513\n",
      "- F-score (macro) 0.1392\n",
      "- Accuracy 0.1522\n",
      "\n",
      "By class:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          ACTOR     0.0789    0.1736    0.1085       812\n",
      "          GENRE     0.2819    0.2292    0.2528      1117\n",
      "           YEAR     0.3815    0.6056    0.4681       720\n",
      "         RATING     0.6690    0.7720    0.7168       500\n",
      "       DIRECTOR     0.1739    0.0965    0.1241       456\n",
      "          TITLE     0.0000    0.0000    0.0000       562\n",
      "           PLOT     0.0000    0.0000    0.0000       491\n",
      "RATINGS_AVERAGE     0.0000    0.0000    0.0000       451\n",
      "      CHARACTER     0.0000    0.0000    0.0000        90\n",
      "         REVIEW     0.0000    0.0000    0.0000        56\n",
      "           SONG     0.0000    0.0000    0.0000        54\n",
      "        TRAILER     0.0000    0.0000    0.0000        30\n",
      "\n",
      "      micro avg     0.2680    0.2366    0.2513      5339\n",
      "      macro avg     0.1321    0.1564    0.1392      5339\n",
      "   weighted avg     0.1999    0.2366    0.2103      5339\n",
      "    samples avg     0.1522    0.1522    0.1522      5339\n",
      "\n",
      "2022-09-07 01:36:23,415 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 8. iteration\n",
    "for i in range(iterations):\n",
    "    # 9. query labeled sentences\n",
    "    queried_samples, labeled_sentences = learner.query(\n",
    "        labeled_sentences, query_number, token_based=token_based, research_mode=True\n",
    "    )\n",
    "\n",
    "    # 10. retrain model, the queried_samples will be added to corpus.train\n",
    "    learner.teach(queried_samples, dir_path=f\"output/retrain_{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9, the `learner.query()` run the query process. The parameter `research_mode` is `True`, which means we just simulate the active learning cycle.\n",
    "\n",
    "The `queried_samples` contains the samples selected by the sampling method. The `labeled_setence` contains the rest data.\n",
    "\n",
    "\n",
    "Related tutorial: [Research and Annotation Mode](../docs/TUTORIAL_5_Research_and_Annotation_Mode.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `learner.teach()` will add `queried_sampels` to the training dataset and retrain the model from scratch. The retraining log and model will be saved to `dir_path`.\n",
    "\n",
    "The whole script can be found in `examples/active_learning_cycle_research_mode.py`."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e065247030c9216ed33624f20c54f671a416ca6030785113c75cd1b8e233e922"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('seqal-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
